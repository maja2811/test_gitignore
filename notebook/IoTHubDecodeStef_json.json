{
	"name": "IoTHubDecodeStef_json",
	"properties": {
		"folder": {
			"name": "IoTHubDecodeStef"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "IoT",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "ee4936c5-7830-48e1-b46f-a51d32c752d0"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/b3aa98da-48aa-4bc9-aba1-effeb7407b42/resourceGroups/rg-atlas-synapse-analytics-dev/providers/Microsoft.Synapse/workspaces/atlas-synapse-analytics-dev/bigDataPools/IoT",
				"name": "IoT",
				"type": "Spark",
				"endpoint": "https://atlas-synapse-analytics-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/IoT",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net",
					"authHeader": null
				},
				"sparkVersion": "3.3",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"extraHeader": null
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "python"
					},
					"collapsed": false
				},
				"source": [
					"%%pyspark\r\n",
					"df = spark.read.load('abfss://iothubsmarttraincontainer@datalakegen2atlasdev.dfs.core.windows.net/iothub-atlas-ext-dev/02/2023/04/17/03/04.json', format='json')\r\n",
					"display(df.limit(10))"
				],
				"execution_count": 40
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import json\r\n",
					"import base64\r\n",
					"from datetime import datetime\r\n",
					"\r\n",
					"# Read the dataframe\r\n",
					"df = spark.read.load('abfss://iothubsmarttraincontainer@datalakegen2atlasdev.dfs.core.windows.net/iothub-atlas-ext-dev/02/2023/04/17/03/04.json', format='json')\r\n",
					"\r\n",
					"# Initialize an empty list to store the data\r\n",
					"data_list = []\r\n",
					"\r\n",
					"# Loop through the rows\r\n",
					"for row in df.collect():\r\n",
					"    # Decode the Base64-encoded string in the \"Body\" column\r\n",
					"    decoded_body = base64.b64decode(row.Body).decode('utf-8')\r\n",
					"    # Parse the JSON string\r\n",
					"    json_data = json.loads(decoded_body)\r\n",
					"    # Convert the JSON object to an array containing the JSON object\r\n",
					"    json_array = json_data\r\n",
					"    print(json_array)\r\n",
					"\r\n",
					"# Output\r\n",
					"# [{'data': 'A2cCAQRoOQ==', 'obj': {'applicationID': '1', 'applicationName': 'cloud', 'data': 'A2cCAQRoOQ==', 'devEUI': '24e124136b325536', 'deviceName': 'Temp2', 'fCnt': 93, 'fPort': 85, 'rxInfo': [{'altitude': 0, 'latitude': 0, 'loRaSNR': 13.5, 'longitude': 0, 'mac': '24e124fffef3d367', 'name': 'Local Gateway', 'rssi': -42, 'time': '2023-03-08T13:05:56.013261Z'}], 'time': '2023-03-08T13:05:56.013261Z', 'txInfo': {'adr': True, 'codeRate': '4/5', 'dataRate': {'bandwidth': 125, 'modulation': 'LORA', 'spreadFactor': 7}, 'frequency': 868300000}}, 'port': 85}]\r\n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import json\r\n",
					"import base64\r\n",
					"\r\n",
					"# Read the dataframe\r\n",
					"df = spark.read.load('abfss://iothubsmarttraincontainer@datalakegen2atlasdev.dfs.core.windows.net/iothub-atlas-ext-dev/02/2023/04/17/03/04.json', format='json')\r\n",
					"\r\n",
					"# Initialize an empty list to store the data\r\n",
					"data_list = []\r\n",
					"\r\n",
					"# Loop through the rows\r\n",
					"for row in df.collect():\r\n",
					"    # Decode the Base64-encoded string in the \"Body\" column\r\n",
					"    decoded_body = base64.b64decode(row.Body).decode('utf-8')\r\n",
					"    # Parse the JSON string\r\n",
					"    json_data = json.loads(decoded_body)\r\n",
					"    # Convert the JSON object to an array containing the JSON object\r\n",
					"    json_array = json_data\r\n",
					"    print(json_array)\r\n",
					"\r\n",
					"    # extract the \"data\" object inside the \"obj\" object\r\n",
					"    \r\n",
					"    data = json_data[\"obj\"][\"data\"]\r\n",
					"    devEUI = json_data[\"obj\"][\"devEUI\"]\r\n",
					"    # print(devEUI)\r\n",
					"    deviceName = json_data[\"obj\"][\"deviceName\"]\r\n",
					"    print(deviceName)\r\n",
					"    # parse the \"data\" object as JSON\r\n",
					"    port = json_data[\"obj\"][\"fPort\"]\r\n",
					"    # retrieve the second string from the list\r\n",
					"    # if there is a Z 0 offset\r\n",
					"    # Extract the time from the JSON data\r\n",
					"    timeUTCOffset = json_data[\"obj\"][\"time\"]\r\n",
					"    print(data)\r\n",
					"    print(port)\r\n",
					"    # add the extracted data to the list\r\n",
					"    # data_list.append(data)\r\n",
					"\r\n",
					"    # Parse the time string as a datetime object\r\n",
					"    time_obj = datetime.fromisoformat(timeUTCOffset.replace(\"Z\", \"+00:00\"))\r\n",
					"    time = time_obj.strftime(\"%Y-%m-%d %H:%M:%S\")\r\n",
					"    # Print the time object in a more readable format\r\n",
					"    print(time)\r\n",
					"\r\n",
					"    data_list.append({\"data\": data, \"port\": port, \"time\": time, \"devEUI\": devEUI, \"deviceName\": deviceName})   \r\n",
					"#print the list of extracted data\r\n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import base64\r\n",
					"\r\n",
					"def decode_base64_and_print_hex(encoded_string):\r\n",
					"    # Decode the Base64-encoded string\r\n",
					"    decoded_bytes = base64.b64decode(encoded_string)\r\n",
					"\r\n",
					"    byte_list = [b for b in decoded_bytes]\r\n",
					"    print(byte_list)\r\n",
					"\r\n",
					"    byte_result2 = []\r\n",
					"    for x in byte_list:   \r\n",
					"        byte_result2.append(hex(x))\r\n",
					"\r\n",
					"    print(byte_result2)\r\n",
					"\r\n",
					"    byte_result = []\r\n",
					"    for num in byte_result2:\r\n",
					"        if int(num, 16) < 10:\r\n",
					"            byte_result.append('0x0' + num[2:])\r\n",
					"        else:\r\n",
					"            byte_result.append(num)\r\n",
					"\r\n",
					"    print('h', byte_result)\r\n",
					"    return byte_result\r\n",
					"\r\n",
					"# Call the function with the encoded_string as an input\r\n",
					"encoded_string = 'A2flAARoQw=='\r\n",
					"result = decode_base64_and_print_hex(encoded_string)\r\n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Define a bytes object with two elements\r\n",
					"byte_result3 = bytes([int('0x7f', 16), int('0x00', 16)])\r\n",
					"\r\n",
					"# Extract the second byte (0x00) and shift it left by 8 bits,\r\n",
					"# resulting in 0x0000. Use bitwise OR to combine the shifted value\r\n",
					"# with the first byte (0x7f), resulting in 0x7f00.\r\n",
					"shifted_bytes = bytes([(byte_result3[1] << 8) | byte_result3[0]])\r\n",
					"\r\n",
					"# Print the resulting bytes object as a hexadecimal string\r\n",
					"print(hex(int.from_bytes(shifted_bytes, byteorder='big')))\r\n",
					"# Output: 0x7f00\r\n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def decode(fPort, hex_strings):\r\n",
					"    # Convert the hexadecimal strings to integers\r\n",
					"    int_list = [int(hex_str, 16) for hex_str in hex_strings]\r\n",
					"\r\n",
					"    # Create a bytearray object from the list of integers\r\n",
					"    byte_result = bytearray(int_list)\r\n",
					"\r\n",
					"    decoded = {}\r\n",
					"\r\n",
					"    i = 0\r\n",
					"    while i < len(byte_result):\r\n",
					"        channel_id = byte_result[i]\r\n",
					"        i += 1\r\n",
					"        channel_type = byte_result[i]\r\n",
					"        i += 1\r\n",
					"        print('Channel Id: ' + str(channel_id) + ' ' + 'Channel Type: ' + str(channel_type))\r\n",
					"\r\n",
					"        # BATTERY\r\n",
					"        if channel_id == 0x01 and channel_type == 0x75:\r\n",
					"            decoded['battery'] = byte_result[i]\r\n",
					"            i += 1\r\n",
					"        # TEMPERATURE\r\n",
					"        elif channel_id == 0x03 and channel_type == 0x67:\r\n",
					"            decoded['temperature'] = readInt16LE(byte_result[i:i+2]) / 10\r\n",
					"            i += 2\r\n",
					"        # HUMIDITY\r\n",
					"        elif channel_id == 0x04 and channel_type == 0x68:\r\n",
					"            decoded['humidity'] = byte_result[i] / 2\r\n",
					"            i += 1\r\n",
					"        # ANGLE\r\n",
					"        elif channel_id == 0x03 and channel_type == 0xcf:\r\n",
					"            decoded['angle_x'] = readInt16LE(byte_result[i:i+2]) / 100\r\n",
					"            decoded['angle_y'] = readInt16LE(byte_result[i+2:i+4]) / 100\r\n",
					"            decoded['angle_z'] = readInt16LE(byte_result[i+4:i+6]) / 100\r\n",
					"            decoded['threshold_x'] = 'trigger' if byte_result[i+6] & 0x01 == 0x01 else 'normal'\r\n",
					"            decoded['threshold_y'] = 'trigger' if byte_result[i+6] & 0x02 == 0x02 else 'normal'\r\n",
					"            decoded['threshold_z'] = 'trigger' if byte_result[i+6] & 0x04 == 0x04 else 'normal'\r\n",
					"            i += 7\r\n",
					"        # DISTANCE\r\n",
					"        elif channel_id == 0x03 and channel_type == 0x82:\r\n",
					"            decoded['distance'] = readUInt16LE(byte_result[i:i+2])\r\n",
					"            i += 2\r\n",
					"        else:\r\n",
					"            print(channel_id, channel_type)\r\n",
					"            break\r\n",
					"\r\n",
					"    return decoded\r\n",
					"\r\n",
					"def readUInt16LE(bytes):\r\n",
					"    value = (bytes[1] << 8) + bytes[0]\r\n",
					"    return value & 0xffff\r\n",
					"\r\n",
					"def readInt16LE(bytes):\r\n",
					"    ref = readUInt16LE(bytes)\r\n",
					"    return ref - 0x10000 if ref > 0x7fff else ref\r\n",
					"\r\n",
					""
				],
				"execution_count": 32
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"updated_dicts = []\r\n",
					"for data_dict in data_list:\r\n",
					"    encoded_string1 = data_dict[\"data\"]\r\n",
					"    port = data_dict[\"port\"]\r\n",
					"    \r\n",
					"    hex_strings = decode_base64_and_print_hex(encoded_string1)\r\n",
					"    decoded_result = decode(port, hex_strings)\r\n",
					"    #print(\"datalist: \", data_list)\r\n",
					"    updated_dict = {**data_dict, **decoded_result}\r\n",
					"    updated_dicts.append(updated_dict)\r\n",
					"    #print(decoded_result)\r\n",
					"    #print(\"updateddict: \", updated_dict)\r\n",
					"print(\"updated: \", updated_dicts)"
				],
				"execution_count": 33
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"#kør bare en ind først. skal være et forloop\r\n",
					"import pandas as pd\r\n",
					"import warnings \r\n",
					"from pyspark.sql import SparkSession\r\n",
					"warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"iteritems is deprecated\")\r\n",
					"data = updated_dicts\r\n",
					"pdf= pd.DataFrame(data)\r\n",
					"df2 = spark.createDataFrame(pdf)\r\n",
					"print(data)\r\n",
					"print(df2)\r\n",
					"display(df2)\r\n",
					"df2.printSchema()"
				],
				"execution_count": 34
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"output_path = \"abfss://zone-connected@datalakegen2atlasdev.dfs.core.windows.net/IoTTestStef/database_test/\"\r\n",
					"\r\n",
					"# Save the DataFrame as a Parquet file in the specified path using append mode\r\n",
					"df2.write.mode(\"append\").parquet(output_path)"
				],
				"execution_count": 35
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Read the parquet files\r\n",
					"parquet_path = \"abfss://zone-connected@datalakegen2atlasdev.dfs.core.windows.net/IoTTestStef/database_test/*.snappy.parquet\"\r\n",
					"parquet_df = spark.read.parquet(parquet_path)\r\n",
					"\r\n",
					"# Register the DataFrame as a SQL temporary view\r\n",
					"parquet_df.createOrReplaceTempView(\"result\")\r\n",
					"\r\n",
					"# Now you can run SQL queries\r\n",
					"result_df = spark.sql(\"SELECT * FROM result\")\r\n",
					"result_df.show()\r\n",
					""
				],
				"execution_count": 36
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Convert PySpark DataFrame to pandas DataFrame\r\n",
					"result_pd = result_df.toPandas()\r\n",
					"\r\n",
					"# Display the top rows in a tabular format\r\n",
					"pd.set_option('display.max_columns', None)  # This line is optional; it ensures that all columns are displayed\r\n",
					"print(result_pd.head())"
				],
				"execution_count": 37
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Read the parquet files\r\n",
					"#parquet_path = \"abfss://zone-connected@datalakegen2atlasdev.dfs.core.windows.net/IoTTestStef/Test/*.snappy.parquet\"\r\n",
					"#parquet_df = spark.read.parquet(parquet_path)\r\n",
					"\r\n",
					"# Save the DataFrame as a table\r\n",
					"#table_name = \"IotStef_Test\"\r\n",
					"#parquet_df.write.saveAsTable(table_name, mode=\"append\")\r\n",
					"\r\n",
					"#query = \"SELECT * FROM IotStef_Test\"\r\n",
					"#result_df = spark.sql(query)\r\n",
					"\r\n",
					"# Perform any transformations or actions on the DataFrame\r\n",
					"#result_df.show()"
				],
				"execution_count": 38
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"select * from result\r\n",
					""
				],
				"execution_count": 39
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					""
				]
			}
		]
	}
}